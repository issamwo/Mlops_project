{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\frup00090410\\\\Mlops_project\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\frup00090410\\\\Mlops_project'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainingConfig:\n",
    "    root_dir: Path\n",
    "    preprocessed_spilitted_data_path: Path\n",
    "    model_path: Path\n",
    "    batch_size: int\n",
    "    epochs: int\n",
    "    max_words: int\n",
    "    validation_split: float\n",
    "    learning_rate: float\n",
    "    beta_1: float\n",
    "    beta_2: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Classifier.constants import *\n",
    "from Classifier.utils.common import read_yaml, create_directories, write_to_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def get_model_training_config(self) -> ModelTrainingConfig:\n",
    "        config = self.config.model_training\n",
    "        \n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_training_config = ModelTrainingConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            preprocessed_spilitted_data_path=Path(config.preprocessed_spilitted_data_path),\n",
    "            model_path=Path(config.model_path),\n",
    "            batch_size=self.params.BATCH_SIZE,\n",
    "            epochs=self.params.EPOCHS,\n",
    "            max_words=self.params.MAX_WORDS,\n",
    "            validation_split=self.params.VALIDATION_SPLIT,\n",
    "            learning_rate=self.params.LEARNING_RATE,\n",
    "            beta_1=self.params.BETA_1,\n",
    "            beta_2=self.params.BETA_2\n",
    "        )\n",
    "\n",
    "        return model_training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from cnnClassifier import logger\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras import optimizers\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTraining:\n",
    "    def __init__(self, config: ModelTrainingConfig): \n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    def read_pickle_files(self):\n",
    "        data = {}\n",
    "        for filename in os.listdir(self.config.preprocessed_spilitted_data_path):\n",
    "            if filename.endswith('.pickle'):\n",
    "                with open(os.path.join(self.config.preprocessed_spilitted_data_path, filename), 'rb') as f:\n",
    "                    data[filename] = pickle.load(f)\n",
    "        return data\n",
    "    \n",
    "    def train_model(self, data: dict):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            data (dict): _description_\n",
    "        \"\"\"\n",
    "\n",
    "        x_train = data['X_train_preprocessed.pickle']\n",
    "        y_train = data['y_train_preprocessed.pickle']\n",
    "        x_test = data['X_test_preprocessed.pickle']\n",
    "        y_test = data['y_test_preprocessed.pickle']\n",
    "\n",
    "        num_classes = y_train.shape[1]\n",
    "\n",
    "        # logger\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(512, input_shape=(self.config.max_words,)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(num_classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        \n",
    "        # create an optimizer instance\n",
    "        adam = optimizers.Adam(learning_rate=self.config.learning_rate, beta_1=self.config.beta_1,\\\n",
    "                                beta_2=self.config.beta_2, epsilon=1e-08, decay=0.0, amsgrad=False)\n",
    "\n",
    "        # compile your model with the optimizer\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "        # \n",
    "        model.fit(x_train, y_train, batch_size=self.config.batch_size,\\\n",
    "                   epochs=self.config.epochs, verbose=1, validation_split=self.config.validation_split)\n",
    "        \n",
    "        model.save(os.path.join(self.config.model_path, 'model.h5'))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-26 10:11:05,515: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-12-26 10:11:05,525: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-12-26 10:11:05,528: INFO: common: created directory at: artifacts]\n",
      "[2023-12-26 10:11:05,533: INFO: common: created directory at: artifacts/model_training]\n"
     ]
    }
   ],
   "source": [
    "config = ConfigurationManager()\n",
    "model_training_config = config.get_model_training_config()\n",
    "model_training = ModelTraining(config=model_training_config)\n",
    "model_training.train_model(model_training.read_pickle_files())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
